---
title: 一种高性能的 Kafka 消费模型
date: 2023-09-16 20:44:44
updated: 2023-09-16 20:45:44
excerpt: 本文介绍了一种基于 Golang 的高性能 Kafka 消费模型
categories: tech
math: true
tags: 
  - Golang
  - Kafka
---

> Kafka 无疑是现在最流行的消息队列。



## 闲话

对于消息队列的选型，在国内环境中， RocketMQ 是一个强大的对手，网络上也有各种各样的对比和指导思想，有兴趣的读者可以自行搜索查看，在本文中并不会让这两者分个高下。

网络上林林总总的文档中，比较有参考意义的是 Apache RocketMQ 官方文档中的对比：[Apache RocketMQ 5.0 中文文档](https://rocketmq.apache.org/zh/docs/)。

可以看到，相比之下RocketMQ 是一个更为“现代化”的消息队列中间件，原生支持了 Kafka 不具备的许多功能，同时也对 Kafka 已有的功能做了一些补充和改进。同时，从文中也可以看到 RocketMQ 相比 Kafka 有着“低延时”和“高可用”的优点，但 Kafka 相比之下拥有更高的“吞吐量”。

此外，官方文档中没有对两者的性能做出详细的说明，而阿里巴巴官方在外网发布了这篇文章作为补充：[基于 Topic 数量的性能压测](https://alibaba-cloud.medium.com/kafka-vs-rocketmq-multiple-topic-stress-test-results-d27b8cbb360f)。



但是，就笔者的经验来说，在大部分实际的技术选型中，有以下三个“反直觉”的真相：

1. 许多细节上的差异并不会给项目带来明显的优势。举一个实际的例子来说：在绝大部分情况下，将接口响应时间从 10s 优化至 100ms，对比将响应时间从 100ms 优化至 1ms ，给用户带来的体感是完全不同的（后者远小于前者），同时付出的成本也是完全不同的（后者远大于前者）。
2. 社区活跃度的重要程度往往被我们轻视——当你遇见问题的时候，更活跃的社区往往能给你带来更短的定位 / 解决时间。这里是一个自带活跃度对比的外网社区的统计结果：[社区活跃度的对比](https://stackshare.io/stackups/kafka-vs-rocketmq)。从中可以看到，RocketMQ 在全球范围内的社区影响力远低于 Kafka。
3. 不同的公司的技术选型思路有巨大的差异。举例来说，我在字节跳动工作期间，公司内部所使用的云平台是自研的“字节云”。在字节云中，从 Golang 的镜像，到云服务器的 Linux 内核，都是公司自研的——根据公司的实际情况做出了相应的优化。当时在云平台的官方文档中，基础架构的同学写下了一段大致如下的描述：“强烈推荐各业务方从 Kafka / BMQ 切换到 RocketMQ，当前字节云中的 RocketMQ 中间件从各方位对比前者都有显著的优势” —— 有时候，只需要这样一句话，就能打消业务方几乎所有的疑问和顾虑（同时也解决了 2 中所描述的社区问题）。

总的来说，所有技术选型都应该基于实际情况进行决策。就像 CAP 定理和“软件工程没有银弹”一样，世界上没有完美的解决方案，到底是否应该“以牺牲部分吞吐量为代价，来获得 RocketMQ 同步刷盘的能力”，还是“它们都太差了，我要自研一款属于我的 MQ”，是需要根据实际业务场景来决定的。

而我现在所处的公司，在决策时面临的困难显然不那么强烈——我们使用亚马逊的 AWS 来部署服务，而 AWS 官方并没有提供基于 RocketMQ 的 Paas 服务，但 AWS MSK （Managed Streaming for Apache Kafka）已经相当成熟了，我们也就自然而然的选择了 Kafka 作为我们的消息队列，事实也证明，即便是和阿里一样同样置身在金融行业中，我们使用了所谓相比之下没有那么“高可靠、低延时”的 Kafka，也并没有给我们带来任何的困扰。



## 正文

### 基于 Golang 的 Kafka SDK

相同的中间件在不同编程语言中的实现的 SDK 必然是有差异的，它们往往会根据语言自身的特点做出相应的适配和优化。我所采用的 sdk 是 segmentio 公司研发的 [kafka-go](https://github.com/segmentio/kafka-go)，是 golang 中非常流行的一个库，也是适配得较好的一个库。

这个库的实现原理大致如下：

![kafka-go sdk](/img/kafka-go/kafka-go-sdk.png)

1. kafka-go 会向 Kafka Broker 拉取一定数量的消息放入内存中的 msg chan（该 chan 的缓存大小是可配置的）
2. 然后应用程序通过调用 `FetchMessage` 方法来从这个 chan 中获取到一个消息并进行消费
3. 当消费成功后，应用程序通过调用 `CommitMessages` 方法来提交 commit request
4. 根据配置，kafka-go 会将 commit chan 中的请求立即提交，或将其 merge 合并为一个请求异步提交



### 简单的阻塞消费模型

最简单的消费模型其实和上面描述的过程是一致的，如下：

![一次消费一条消息](/img/kafka-go/simple.png)

当消费成功时直接提交；当消费失败时，根据需要进行无限重试，或是直接丢弃（提交 commit 请求视为成功）。

---

常用 RocketMQ 的用户可以思考一下为什么我们一定要阻塞在某一条消息的处理上，为什么不能使用一个 `sync.WaitGroup` 来进行一定程度的并发呢？

曾经我在字节工作期间使用 RocketMQ 时，确实是这么做的，就像在接到 HTTP 请求后开启协程来处理一样，在接到消息后也开启协程进行处理。但这是建立在 RocketMQ 本身是支持消息重试的基础上的，当 RocketMQ 消息消费失败后，我们可以显示地向 RocketMQ 提交一个 `NACK` 请求来表明消息处理失败了，此时消息会被 RocketMQ 丢入重试队列中等待二次消费，当失败次数达到阈值后，会被其放进死信队列中，消息永远是不会丢失的。

但对于 Kafka 而言，它的提交行为是不区分 `ACK ` / ` NACK` 的，它的 commit 请求中只包含一个 `offset` 参数来标识当前消费者的消费进度。与此同时，kafka-go sdk 又在内存中将消息缓存到 chan 中，当我开启若干个协程调用 FetchMessage 方法时，获取到的消息是完全不同的。也就是说，当我开启三个协程处理三条消息时，可能分别在处理 offset = `1` / `2` / `3` 的 3 条消息，当 1 和 2 处理失败但 3 处理成功时，一旦将 3 commit 到 Kafka 中，1 和 2 就永久的丢失了（再也不会被消费了）。

---

这种模型虽然很简单，但也十分低效，适合的场景也非常有限，举几个实际的例子：

1. 新增 / 注销账号产生的消息。类似的场景下消息产生的 QPS 很可能 < 1，因此使用该模型并不会造成性能瓶颈，反而在一定程度上可以提升开发效率。
2. 需要使用顺序消费的场景。也就是说，在消费某条消息之前，必须消费完这条消息之前的所有消息，例如涉及到某些状态流转的场景，阶段 A 不能直接转换为阶段 C，而是必须经过阶段 B，此时我们需要顺序消费 A->B、B->C 这两条消息。



### 高性能的批量消费模型

在 Kafka 不支持 `ACK` / `NACK` 的情况之下，是不是就无法使用并发消费了呢？当然不是。接下来将介绍一种可配置、高并发的高性能消费模型：

#### 以 Partition 为维度的并发

熟悉 Kafka 架构的同学可能知道，Kafka 同一个 Topic 下的消息是分为多个 Partition 进行存储的，每个 Partition 中的消息都是按照投递的顺序进行排序的，也就是说，我们在消费同一个 Topic 的情况下，至少可以进行 Partition 维度的并发。

// TODO
